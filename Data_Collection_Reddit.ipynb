{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7347474",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4445b675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ac8ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function 'reddit_to_csv' will take three arguments: \n",
    "# 1. the subreddit being scraped; 2. the filename, or the name\n",
    "# the csv file will be given; and 3. the number of requests \n",
    "# the user would like to make of reddit's API. \n",
    "\n",
    "def reddit_to_csv(subreddit, filename, n_requests=1):\n",
    "    \n",
    "    #Create an empty list to be used later in function:\n",
    "    posts = []\n",
    "    \n",
    "    #Create User-Agent to avoid 429 res.status_code:\n",
    "    headers = {'User-agent':'Eye eye bot 00'}\n",
    "    \n",
    "    #Establish that 'after' (a variable used later) is None type:\n",
    "    after = None\n",
    "    \n",
    "    #for loop n_requests iterations (n_requests is established by user):\n",
    "    for i in range(n_requests):\n",
    "        print(i)\n",
    "        \n",
    "        if after == None:\n",
    "            params = {}\n",
    "        else:\n",
    "            params = {'after': after}\n",
    "        #Assign 'url' to reddit's base url, plus whatever subreddit \n",
    "        #the user provides,plus .json for clean results:\n",
    "        #url = 'https://www.reddit.com/hot.json'\n",
    "        url = 'https://www.reddit.com/' + str(subreddit) + '/.json'\n",
    "        \n",
    "        #Set my res variable equal to the results from requests.get, \n",
    "        #and the parameters set above like 'url' or 'params':\n",
    "        res = requests.get(url,params=params,headers=headers)\n",
    "        \n",
    "        #Conditional statement to ensure access to the API is approved:\n",
    "        if res.status_code ==200:\n",
    "            the_json = res.json()\n",
    "            \n",
    "            for x in range(len(the_json['data']['children'])):\n",
    "                \n",
    "                #Create temporary dictionary to add results of each post to:\n",
    "                temp_dict = {}\n",
    "                #After looking through the json results, I've selected the below information about the posts\n",
    "                #as those that can potentially add value to my model's results.\n",
    "                temp_dict['subreddit'] = the_json['data']['children'][x]['data']['subreddit']\n",
    "                temp_dict['title'] = the_json['data']['children'][x]['data']['title']\n",
    "                temp_dict['post_paragraph'] = the_json['data']['children'][x]['data']['selftext']\n",
    "                temp_dict['clicked'] = the_json['data']['children'][x]['data']['clicked']\n",
    "                temp_dict['ups'] = the_json['data']['children'][x]['data']['ups']\n",
    "                temp_dict['downs'] = the_json['data']['children'][x]['data']['downs']\n",
    "                temp_dict['likes'] = the_json['data']['children'][x]['data']['likes']\n",
    "                temp_dict['category'] = the_json['data']['children'][x]['data']['category']\n",
    "                temp_dict['number_of_comments'] = the_json['data']['children'][x]['data']['num_comments']\n",
    "                temp_dict['score'] = the_json['data']['children'][x]['data']['score']\n",
    "                temp_dict['author_flair_css_class'] = the_json['data']['children'][x]['data']['author_flair_css_class']\n",
    "                temp_dict['subreddit_type'] = the_json['data']['children'][x]['data']['subreddit_type']\n",
    "                \n",
    "                #Add the temporary dictionary to 'posts',the list of each post's dictionary of information:\n",
    "                posts.append(temp_dict)\n",
    "                #posts.extend(the_json['data']['children'])\n",
    "            after = the_json['data']['after']\n",
    "            \n",
    "        else:\n",
    "            print(res.status_code)\n",
    "            break\n",
    "        time.sleep(1)\n",
    "        \n",
    "    #Turn the list of post dictionaries into a pandas DataFrame:\n",
    "    posts_df = pd.DataFrame(posts)\n",
    "    \n",
    "    #Drop any duplicate rows that may have been pulled:\n",
    "    posts_df.drop_duplicates(inplace = True)\n",
    "    \n",
    "    #Rearrange the columns into a more logical order:\n",
    "    posts_df = posts_df[['subreddit', 'title', 'clicked', 'ups', 'downs', 'post_paragraph', 'likes', 'number_of_comments', 'category', 'score', 'author_flair_css_class', 'subreddit_type']]\n",
    "    \n",
    "    #Save the DataFrame as a .csv file:\n",
    "    posts_df.to_csv(str(filename), index = False, sep = \",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba15dbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Load and save the data as CSV\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mreddit_to_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubreddit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr/Mario/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Target Reddit for\u001b[39;49;00m\n\u001b[0;32m      3\u001b[0m \u001b[43m              \u001b[49m\u001b[43mn_requests\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m              \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmario_reddit_posts.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mreddit_to_csv\u001b[1;34m(subreddit, filename, n_requests)\u001b[0m\n\u001b[0;32m     28\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.reddit.com/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(subreddit) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#Set my res variable equal to the results from requests.get, \u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#and the parameters set above like 'url' or 'params':\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241m.\u001b[39mget(url,params\u001b[38;5;241m=\u001b[39mparams,headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#Conditional statement to ensure access to the API is approved:\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m200\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "#Load and save the data as CSV\n",
    "reddit_to_csv(subreddit = 'r/Mario/', # Target Reddit for\n",
    "              n_requests = 150,\n",
    "              filename = 'mario_reddit_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b61d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and save the data as CSV\n",
    "reddit_to_csv(subreddit = 'r/zelda',\n",
    "              n_requests = 150,\n",
    "              filename = 'zelda_reddit_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1afb1064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>clicked</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>post_paragraph</th>\n",
       "      <th>likes</th>\n",
       "      <th>number_of_comments</th>\n",
       "      <th>category</th>\n",
       "      <th>score</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>subreddit_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mario</td>\n",
       "      <td>Super Mario Movie Trailer MEGATHREAD</td>\n",
       "      <td>False</td>\n",
       "      <td>374</td>\n",
       "      <td>0</td>\n",
       "      <td>Want to discuss about the movie trailer? You'r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mario</td>\n",
       "      <td>Karma farming posts get removed, egregious rep...</td>\n",
       "      <td>False</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>First up, apologies for these out of date rule...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                              title  clicked  ups  \\\n",
       "0     Mario               Super Mario Movie Trailer MEGATHREAD    False  374   \n",
       "1     Mario  Karma farming posts get removed, egregious rep...    False  113   \n",
       "\n",
       "   downs                                     post_paragraph  likes  \\\n",
       "0      0  Want to discuss about the movie trailer? You'r...    NaN   \n",
       "1      0  First up, apologies for these out of date rule...    NaN   \n",
       "\n",
       "   number_of_comments  category  score author_flair_css_class subreddit_type  \n",
       "0                 894       NaN    374                    NaN         public  \n",
       "1                   7       NaN    113                    NaN         public  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mario_df = pd.read_csv('./mario_reddit_posts.csv')\n",
    "mario_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b72eca2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2258, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mario_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5975eea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>clicked</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>post_paragraph</th>\n",
       "      <th>likes</th>\n",
       "      <th>number_of_comments</th>\n",
       "      <th>category</th>\n",
       "      <th>score</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>subreddit_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zelda</td>\n",
       "      <td>Today is Self-Post Sunday. Only self-posts are...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Self-Post Sundays are our main discussion day....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>hylian</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zelda</td>\n",
       "      <td>[All] Which of these Creeped You The Most in Z...</td>\n",
       "      <td>False</td>\n",
       "      <td>627</td>\n",
       "      <td>0</td>\n",
       "      <td>Which of these locations, enemies, moments, or...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                              title  clicked  ups  \\\n",
       "0     zelda  Today is Self-Post Sunday. Only self-posts are...    False    0   \n",
       "1     zelda  [All] Which of these Creeped You The Most in Z...    False  627   \n",
       "\n",
       "   downs                                     post_paragraph  likes  \\\n",
       "0      0  Self-Post Sundays are our main discussion day....    NaN   \n",
       "1      0  Which of these locations, enemies, moments, or...    NaN   \n",
       "\n",
       "   number_of_comments  category  score author_flair_css_class subreddit_type  \n",
       "0                   0       NaN      0                 hylian         public  \n",
       "1                 258       NaN    627                    NaN         public  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zelda_df = pd.read_csv('./zelda_reddit_posts.csv')\n",
    "zelda_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab98ace",
   "metadata": {},
   "source": [
    "**Append the Mario and Zelda files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dd6bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([mario_df,zelda_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "720e8b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4712, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eef94e",
   "metadata": {},
   "source": [
    "**CSV CHECKPOINT (check the data again).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1596b325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>clicked</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>post_paragraph</th>\n",
       "      <th>likes</th>\n",
       "      <th>number_of_comments</th>\n",
       "      <th>category</th>\n",
       "      <th>score</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>subreddit_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mario</td>\n",
       "      <td>Super Mario Movie Trailer MEGATHREAD</td>\n",
       "      <td>False</td>\n",
       "      <td>374</td>\n",
       "      <td>0</td>\n",
       "      <td>Want to discuss about the movie trailer? You'r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mario</td>\n",
       "      <td>Karma farming posts get removed, egregious rep...</td>\n",
       "      <td>False</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>First up, apologies for these out of date rule...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario</td>\n",
       "      <td>If there are power ups in the movie, how do yo...</td>\n",
       "      <td>False</td>\n",
       "      <td>425</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mario</td>\n",
       "      <td>I'm still thinking about the Mario Movie so I ...</td>\n",
       "      <td>False</td>\n",
       "      <td>696</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mario</td>\n",
       "      <td>I understand the disappointment of Charles Mar...</td>\n",
       "      <td>False</td>\n",
       "      <td>381</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                              title  clicked  ups  \\\n",
       "0     Mario               Super Mario Movie Trailer MEGATHREAD    False  374   \n",
       "1     Mario  Karma farming posts get removed, egregious rep...    False  113   \n",
       "2     Mario  If there are power ups in the movie, how do yo...    False  425   \n",
       "3     Mario  I'm still thinking about the Mario Movie so I ...    False  696   \n",
       "4     Mario  I understand the disappointment of Charles Mar...    False  381   \n",
       "\n",
       "   downs                                     post_paragraph  likes  \\\n",
       "0      0  Want to discuss about the movie trailer? You'r...    NaN   \n",
       "1      0  First up, apologies for these out of date rule...    NaN   \n",
       "2      0                                                NaN    NaN   \n",
       "3      0                                                NaN    NaN   \n",
       "4      0                                                NaN    NaN   \n",
       "\n",
       "   number_of_comments  category  score author_flair_css_class subreddit_type  \n",
       "0                 894       NaN    374                    NaN         public  \n",
       "1                   7       NaN    113                    NaN         public  \n",
       "2                  59       NaN    425                    NaN         public  \n",
       "3                  29       NaN    696                    NaN         public  \n",
       "4                  94       NaN    381                    NaN         public  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af98a45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2454, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zelda_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7d1a329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2258, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mario_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "509af679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4712"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zelda_df.shape[0]+mario_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2b460db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4712, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3b2a62",
   "metadata": {},
   "source": [
    "**Create a 'target' column (will equal 1 if the post's subreddit is Mario, and 0 if the post's subreddit is Zelda):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5556bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = np.where(df['subreddit'] == 'Mario', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44423322",
   "metadata": {},
   "source": [
    "**Check missing value and drop columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9122a5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit                    0\n",
       "title                        0\n",
       "clicked                      0\n",
       "ups                          0\n",
       "downs                        0\n",
       "post_paragraph            3498\n",
       "likes                     4712\n",
       "number_of_comments           0\n",
       "category                  4712\n",
       "score                        0\n",
       "author_flair_css_class    4078\n",
       "subreddit_type               0\n",
       "target                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5853e9",
   "metadata": {},
   "source": [
    "**The column 'clicked' is not empty, but the column values are purely False, therefore I will drop 'clicked' as well. The same for columns 'downs' and 'subreddit_type' which are purely 0's and 'public', respectively.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee81a4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    4712\n",
       "Name: clicked, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clicked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a90ee0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4712\n",
       "Name: downs, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['downs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4417a8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "public    4712\n",
       "Name: subreddit_type, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6224d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_list = ['likes', 'category', 'clicked', 'downs', 'subreddit_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edc94c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df_drop_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcb55e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4712, 8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "720d3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbf3809a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4710, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dff78f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('master_df.csv', index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2126afcf",
   "metadata": {},
   "source": [
    "# Read CSV in the model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6955644",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./master_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
